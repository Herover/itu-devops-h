=== Scaling Strategy

Out of the two options we were given to implement scaling, we chose the high-availability setup that introduces a second web server to equally share the load with the original. To do this, we provisioned a new server on DigitalOcean through Terraform. This new server was simply created as an exact replica of the original, using Terraform's `count` meta-argumentfootnote:[https://www.terraform.io/language/meta-arguments/count]. In addition, we created a DigitalOcean load balancer through Terraform and connected the two web servers to it, thus allowing it to equally spread requests between them. Of course, all web requests would now have to go through the load balancer, rather than directly to the original web server.

To properly deploy new versions of the application to both web servers through our build chain, we created a https://github.com/Herover/itu-devops-h/blob/main/terraform/files/deploy.sh[script] to execute rolling updates in one of the build steps. This script updates one server, then checks whether it has come back alive. If not, it aborts the update procedure such that the second server will still be online and serving users. At the moment it does not roll back the failed server, though this is something we would like to implement in the future.

This setup definitely improves availability, as it allows for the failure of one web server without the system going down. As long as one server is still running, the application will be able to serve requests. However, the load balancer is still a single point of failure - if that goes down, then the application will not work. As such, a better setup would be to include a second load balancer to act as a standby in case the first goes offline.
